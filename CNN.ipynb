{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction: Document Classification with a CNN\n",
    "\n",
    "In this notebook, we will use a one-dimensional convolutional neural network to classify questions. This is an old method that used to be popular but has since given way to Recurrent networks with LSTM cells."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1099063, 30), (56370, 30), (59728, 300))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only want to use one gpu\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # \"0, 1\" for multiple\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())\n",
    "\n",
    "from utils import load_data\n",
    "\n",
    "seq_arr, test_seq_arr, labels, word_index, index_word, vs, embedding_matrix = load_data('word', 'glove')\n",
    "seq_arr.shape, test_seq_arr.shape, embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import f1\n",
    "import re\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from keras.utils import multi_gpu_model\n",
    "from keras import optimizers\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.callbacks import *\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-Level Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 30, 300)           17918400  \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 29, 128)           76928     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_4 (MaxPooling1 (None, 14, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 13, 128)           32896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_5 (MaxPooling1 (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_6 (Conv1D)            (None, 11, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_6 (MaxPooling1 (None, 1, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 128)               16512     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,094,145\n",
      "Trainable params: 18,094,145\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(seq_arr.shape[1],), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], \n",
    "                             embedding_matrix.shape[1],\n",
    "                             weights = [embedding_matrix],\n",
    "                             name = 'embedding')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "l_cov1= Conv1D(128, 2, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "\n",
    "l_cov2 = Conv1D(128, 2, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(1)(l_cov2)\n",
    "\n",
    "l_cov3 = Conv1D(128, 3, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(11)(l_cov3)\n",
    "\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "l_dense = Dropout(0.5)(l_dense)\n",
    "preds = Dense(1, activation='sigmoid')(l_dense)\n",
    "                          \n",
    "model = Model(inputs = [sequence_input], output = [preds])\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), loss = 'binary_crossentropy',\n",
    "              metrics = ['binary_crossentropy', 'accuracy', f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 659437 samples, validate on 439626 samples\n",
      "Epoch 1/25\n",
      "659437/659437 [==============================] - 30s 45us/step - loss: 0.1374 - binary_crossentropy: 0.1374 - acc: 0.9509 - f1: 0.3901 - val_loss: 0.1120 - val_binary_crossentropy: 0.1120 - val_acc: 0.9561 - val_f1: 0.5237\n",
      "Epoch 2/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.1006 - binary_crossentropy: 0.1006 - acc: 0.9597 - f1: 0.5957 - val_loss: 0.1095 - val_binary_crossentropy: 0.1095 - val_acc: 0.9566 - val_f1: 0.5933\n",
      "Epoch 3/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0862 - binary_crossentropy: 0.0862 - acc: 0.9643 - f1: 0.6647 - val_loss: 0.1160 - val_binary_crossentropy: 0.1160 - val_acc: 0.9568 - val_f1: 0.5587\n",
      "Epoch 4/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0715 - binary_crossentropy: 0.0715 - acc: 0.9704 - f1: 0.7314 - val_loss: 0.1288 - val_binary_crossentropy: 0.1288 - val_acc: 0.9501 - val_f1: 0.5836\n",
      "Epoch 5/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0555 - binary_crossentropy: 0.0555 - acc: 0.9774 - f1: 0.7981 - val_loss: 0.1525 - val_binary_crossentropy: 0.1525 - val_acc: 0.9528 - val_f1: 0.5604\n",
      "Epoch 6/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0410 - binary_crossentropy: 0.0410 - acc: 0.9836 - f1: 0.8541 - val_loss: 0.2056 - val_binary_crossentropy: 0.2056 - val_acc: 0.9497 - val_f1: 0.5549\n",
      "Epoch 7/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0300 - binary_crossentropy: 0.0300 - acc: 0.9880 - f1: 0.8933 - val_loss: 0.2635 - val_binary_crossentropy: 0.2635 - val_acc: 0.9515 - val_f1: 0.5082\n",
      "Epoch 8/25\n",
      "659437/659437 [==============================] - 22s 34us/step - loss: 0.0230 - binary_crossentropy: 0.0230 - acc: 0.9909 - f1: 0.9181 - val_loss: 0.2680 - val_binary_crossentropy: 0.2680 - val_acc: 0.9503 - val_f1: 0.5161\n",
      "Epoch 9/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0181 - binary_crossentropy: 0.0181 - acc: 0.9930 - f1: 0.9371 - val_loss: 0.2902 - val_binary_crossentropy: 0.2902 - val_acc: 0.9483 - val_f1: 0.5221\n",
      "Epoch 10/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0141 - binary_crossentropy: 0.0141 - acc: 0.9946 - f1: 0.9516 - val_loss: 0.3039 - val_binary_crossentropy: 0.3039 - val_acc: 0.9483 - val_f1: 0.5168\n",
      "Epoch 11/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0115 - binary_crossentropy: 0.0115 - acc: 0.9957 - f1: 0.9616 - val_loss: 0.3319 - val_binary_crossentropy: 0.3319 - val_acc: 0.9456 - val_f1: 0.5191\n",
      "Epoch 12/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0096 - binary_crossentropy: 0.0096 - acc: 0.9965 - f1: 0.9686 - val_loss: 0.3656 - val_binary_crossentropy: 0.3656 - val_acc: 0.9483 - val_f1: 0.5210\n",
      "Epoch 13/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0081 - binary_crossentropy: 0.0081 - acc: 0.9971 - f1: 0.9737 - val_loss: 0.3959 - val_binary_crossentropy: 0.3959 - val_acc: 0.9495 - val_f1: 0.5081\n",
      "Epoch 14/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0072 - binary_crossentropy: 0.0072 - acc: 0.9975 - f1: 0.9776 - val_loss: 0.3970 - val_binary_crossentropy: 0.3970 - val_acc: 0.9478 - val_f1: 0.5115\n",
      "Epoch 15/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0061 - binary_crossentropy: 0.0061 - acc: 0.9978 - f1: 0.9802 - val_loss: 0.4162 - val_binary_crossentropy: 0.4162 - val_acc: 0.9454 - val_f1: 0.5174\n",
      "Epoch 16/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0055 - binary_crossentropy: 0.0055 - acc: 0.9980 - f1: 0.9821 - val_loss: 0.4077 - val_binary_crossentropy: 0.4077 - val_acc: 0.9485 - val_f1: 0.5094\n",
      "Epoch 17/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0052 - binary_crossentropy: 0.0052 - acc: 0.9982 - f1: 0.9835 - val_loss: 0.4310 - val_binary_crossentropy: 0.4310 - val_acc: 0.9499 - val_f1: 0.4898\n",
      "Epoch 18/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0046 - binary_crossentropy: 0.0046 - acc: 0.9984 - f1: 0.9860 - val_loss: 0.4185 - val_binary_crossentropy: 0.4185 - val_acc: 0.9480 - val_f1: 0.4977\n",
      "Epoch 19/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0045 - binary_crossentropy: 0.0045 - acc: 0.9985 - f1: 0.9862 - val_loss: 0.4354 - val_binary_crossentropy: 0.4354 - val_acc: 0.9473 - val_f1: 0.5099\n",
      "Epoch 20/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0039 - binary_crossentropy: 0.0039 - acc: 0.9987 - f1: 0.9879 - val_loss: 0.4605 - val_binary_crossentropy: 0.4605 - val_acc: 0.9474 - val_f1: 0.4930\n",
      "Epoch 21/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0040 - binary_crossentropy: 0.0040 - acc: 0.9986 - f1: 0.9878 - val_loss: 0.4382 - val_binary_crossentropy: 0.4382 - val_acc: 0.9457 - val_f1: 0.5038\n",
      "Epoch 22/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0039 - binary_crossentropy: 0.0039 - acc: 0.9987 - f1: 0.9880 - val_loss: 0.4536 - val_binary_crossentropy: 0.4536 - val_acc: 0.9486 - val_f1: 0.5103\n",
      "Epoch 23/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0033 - binary_crossentropy: 0.0033 - acc: 0.9989 - f1: 0.9902 - val_loss: 0.4700 - val_binary_crossentropy: 0.4700 - val_acc: 0.9477 - val_f1: 0.5010\n",
      "Epoch 24/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0031 - binary_crossentropy: 0.0031 - acc: 0.9990 - f1: 0.9907 - val_loss: 0.4728 - val_binary_crossentropy: 0.4728 - val_acc: 0.9476 - val_f1: 0.5009\n",
      "Epoch 25/25\n",
      "659437/659437 [==============================] - 22s 33us/step - loss: 0.0033 - binary_crossentropy: 0.0033 - acc: 0.9989 - f1: 0.9902 - val_loss: 0.4561 - val_binary_crossentropy: 0.4561 - val_acc: 0.9491 - val_f1: 0.4976\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cnn_word'\n",
    "\n",
    "# Create callbacks\n",
    "callback_list = [EarlyStopping(monitor = 'val_loss', patience = 4),\n",
    "                 ModelCheckpoint(f'models/{model_name}.h5', monitor = 'val_loss',\n",
    "                                 save_best_only = True)]\n",
    "\n",
    "history = model.fit(seq_arr, labels, validation_split = 0.4,\n",
    "                    epochs = 25, batch_size = 1024,\n",
    "                    callbacks = callbacks_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_name, embedding_name):\n",
    "    if embedding_name == 'wiki':\n",
    "        if data_name == 'word':\n",
    "            embedding_matrix = np.load('word_wiki_embeddings.npy')\n",
    "    elif embedding_name == 'glove':\n",
    "        if data_name == 'word':\n",
    "            embedding_matrix = np.load('word_glove_embeddings.npy')\n",
    "            \n",
    "    if data_name == 'word':\n",
    "        seq_arr = np.load('word_sequences.npy')\n",
    "        test_seq_arr = np.load('test_word_sequences.npy')\n",
    "        labels = np.load('word_labels.npy')\n",
    "        iw = []\n",
    "        with open('word_index_word.json', 'r') as f:\n",
    "            for l in f:\n",
    "                iw.append(json.loads(l))\n",
    "\n",
    "        index_word = iw[0]\n",
    "        index_word = {int(key): word for key, word in index_word.items()}\n",
    "\n",
    "        wi = []\n",
    "        with open('word_word_index.json', 'r') as f:\n",
    "            for l in f:\n",
    "                wi.append(json.loads(l))\n",
    "\n",
    "        word_index = wi[0]\n",
    "        word_index = {word: int(index) for word, index in word_index.items()}\n",
    "            \n",
    "        vs = len(word_index)\n",
    "        \n",
    "    elif data_name == 'char':\n",
    "        seq_arr = np.load('char_sequences.npy')\n",
    "        test_seq_arr = np.load('test_char_sequences.npy')\n",
    "        labels = np.load('char_labels.npy')\n",
    "        iw = []\n",
    "        with open('char_index_word.json', 'r') as f:\n",
    "            for l in f:\n",
    "                iw.append(json.loads(l))\n",
    "\n",
    "        index_word = iw[0]\n",
    "        index_word = {int(key): word for key, word in index_word.items()}\n",
    "\n",
    "        wi = []\n",
    "        with open('char_word_index.json', 'r') as f:\n",
    "            for l in f:\n",
    "                wi.append(json.loads(l))\n",
    "\n",
    "        word_index = wi[0]\n",
    "        word_index = {word: int(index) for word, index in word_index.items()}\n",
    "        \n",
    "        vs = len(word_index)\n",
    "        \n",
    "        embedding_matrix = np.zeros((vs, 100))\n",
    "            \n",
    "    return seq_arr, test_seq_arr, labels, word_index, index_word, vs, embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "seq_arr, test_seq_arr, labels, word_index, index_word, vs, embedding_matrix = load_data('char', embedding_name = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 100)          32300     \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 149, 128)          25728     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 74, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 73, 128)           32896     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 73, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 71, 128)           49280     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 6, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 768)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               98432     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 238,765\n",
      "Trainable params: 238,765\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(seq_arr.shape[1],), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], \n",
    "                             embedding_matrix.shape[1],\n",
    "                             weights = [embedding_matrix],\n",
    "                             name = 'embedding')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "l_cov1= Conv1D(128, 2, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "\n",
    "l_cov2 = Conv1D(128, 2, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(1)(l_cov2)\n",
    "\n",
    "l_cov3 = Conv1D(128, 3, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(11)(l_cov3)\n",
    "\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "\n",
    "l_dense = Dropout(0.5)(l_dense)\n",
    "preds = Dense(1, activation='sigmoid')(l_dense)\n",
    "                          \n",
    "model = Model(inputs = [sequence_input], output = [preds])\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), loss = 'binary_crossentropy',\n",
    "              metrics = ['binary_crossentropy', 'accuracy', f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 708671 samples, validate on 472448 samples\n",
      "Epoch 1/25\n",
      "708671/708671 [==============================] - 33s 47us/step - loss: 0.5652 - binary_crossentropy: 0.5652 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.4611 - val_binary_crossentropy: 0.4611 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 2/25\n",
      "708671/708671 [==============================] - 33s 46us/step - loss: 0.3932 - binary_crossentropy: 0.3932 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.3391 - val_binary_crossentropy: 0.3391 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 3/25\n",
      "708671/708671 [==============================] - 33s 46us/step - loss: 0.3032 - binary_crossentropy: 0.3032 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2755 - val_binary_crossentropy: 0.2755 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 4/25\n",
      "708671/708671 [==============================] - 32s 46us/step - loss: 0.2563 - binary_crossentropy: 0.2563 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2425 - val_binary_crossentropy: 0.2425 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 5/25\n",
      "708671/708671 [==============================] - 32s 45us/step - loss: 0.2319 - binary_crossentropy: 0.2319 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2256 - val_binary_crossentropy: 0.2256 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 6/25\n",
      "708671/708671 [==============================] - 32s 45us/step - loss: 0.2198 - binary_crossentropy: 0.2198 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2176 - val_binary_crossentropy: 0.2176 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 7/25\n",
      "708671/708671 [==============================] - 32s 46us/step - loss: 0.2142 - binary_crossentropy: 0.2142 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2142 - val_binary_crossentropy: 0.2142 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 8/25\n",
      "708671/708671 [==============================] - 32s 45us/step - loss: 0.2120 - binary_crossentropy: 0.2120 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2130 - val_binary_crossentropy: 0.2130 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 9/25\n",
      "708671/708671 [==============================] - 32s 45us/step - loss: 0.2113 - binary_crossentropy: 0.2113 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2128 - val_binary_crossentropy: 0.2128 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 10/25\n",
      "708671/708671 [==============================] - 32s 46us/step - loss: 0.2112 - binary_crossentropy: 0.2112 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2127 - val_binary_crossentropy: 0.2127 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 11/25\n",
      "708671/708671 [==============================] - 32s 46us/step - loss: 0.2111 - binary_crossentropy: 0.2111 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2128 - val_binary_crossentropy: 0.2128 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 12/25\n",
      "708671/708671 [==============================] - 32s 45us/step - loss: 0.2111 - binary_crossentropy: 0.2111 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2128 - val_binary_crossentropy: 0.2128 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 13/25\n",
      "708671/708671 [==============================] - 32s 46us/step - loss: 0.2111 - binary_crossentropy: 0.2111 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2128 - val_binary_crossentropy: 0.2128 - val_acc: 0.9451 - val_f1: 0.0000e+00\n",
      "Epoch 14/25\n",
      "708671/708671 [==============================] - 33s 46us/step - loss: 0.2111 - binary_crossentropy: 0.2111 - acc: 0.9456 - f1: 0.0000e+00 - val_loss: 0.2128 - val_binary_crossentropy: 0.2128 - val_acc: 0.9451 - val_f1: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "model_name = 'cnn_char'\n",
    "\n",
    "# Create callbacks\n",
    "callback_list = [EarlyStopping(monitor = 'val_loss', patience = 4),\n",
    "                 ModelCheckpoint(f'models/{model_name}.h5', monitor = 'val_loss',\n",
    "                                 save_best_only = True)]\n",
    "\n",
    "history = model.fit(seq_arr, labels, validation_split = 0.4,\n",
    "                    epochs = 25, batch_size = 1024,\n",
    "                    callbacks = callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 150)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 150, 100)          32300     \n",
      "_________________________________________________________________\n",
      "conv1d_16 (Conv1D)           (None, 149, 256)          51456     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_16 (MaxPooling (None, 74, 256)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_17 (Conv1D)           (None, 73, 512)           262656    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 36, 512)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_18 (Conv1D)           (None, 34, 256)           393472    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 6, 256)            0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 1536)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 128)               196736    \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 64)                0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 1)                 65        \n",
      "=================================================================\n",
      "Total params: 944,941\n",
      "Trainable params: 944,941\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "sequence_input = Input(shape=(seq_arr.shape[1],), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], \n",
    "                             embedding_matrix.shape[1],\n",
    "                             weights = [embedding_matrix],\n",
    "                             name = 'embedding')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "l_cov1= Conv1D(256, 2, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "\n",
    "l_cov2 = Conv1D(512, 2, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(2)(l_cov2)\n",
    "\n",
    "l_cov3 = Conv1D(256, 3, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(5)(l_cov3)\n",
    "\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "l_dense = Dropout(0.5)(l_dense)\n",
    "\n",
    "l_dense = Dense(64, activation = 'relu')(l_dense)\n",
    "l_dense = Dropout(0.5)(l_dense)\n",
    "\n",
    "preds = Dense(1, activation='sigmoid')(l_dense)\n",
    "                          \n",
    "model = Model(inputs = [sequence_input], output = [preds])\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), loss = 'binary_crossentropy',\n",
    "              metrics = ['binary_crossentropy', 'accuracy', f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 708671 samples, validate on 472448 samples\n",
      "Epoch 1/25\n",
      "  7168/708671 [..............................] - ETA: 2:34 - loss: 0.6920 - binary_crossentropy: 0.6920 - acc: 0.9478 - f1: 0.0000e+00"
     ]
    }
   ],
   "source": [
    "model_name = 'cnn_char'\n",
    "\n",
    "# Create callbacks\n",
    "callback_list = [EarlyStopping(monitor = 'val_loss', patience = 5),\n",
    "                 ModelCheckpoint(f'models/{model_name}.h5', monitor = 'val_loss',\n",
    "                                 save_best_only = True)]\n",
    "\n",
    "history = model.fit(seq_arr, labels, validation_split = 0.4,\n",
    "                    epochs = 25, batch_size = 1024,\n",
    "                    callbacks = callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
