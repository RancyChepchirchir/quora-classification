{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:GPU:0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((1099063, 30), (56370, 30), (59728, 300))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only want to use one gpu\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\" # so the IDs match nvidia-smi\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"1\" # \"0, 1\" for multiple\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "print(get_available_gpus())\n",
    "\n",
    "from utils import load_data\n",
    "\n",
    "seq_arr, test_seq_arr, labels, word_index, index_word, vs, embedding_matrix = load_data('word', 'glove')\n",
    "seq_arr.shape, test_seq_arr.shape, embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import *\n",
    "from keras import callbacks\n",
    "from timeit import default_timer as timer\n",
    "from keras import models, losses, metrics, layers, optimizers\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "datadir = '/home/wjk68/data/quora/'\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word-Level Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_9 (InputLayer)         (None, 30)                0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 30, 300)           17918400  \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 26, 128)           192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_17 (MaxPooling (None, 13, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 9, 128)            82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_18 (MaxPooling (None, 9, 128)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_24 (Conv1D)           (None, 5, 128)            82048     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 640)               0         \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 128)               82048     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,356,801\n",
      "Trainable params: 18,356,801\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:24: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "sequence_input = Input(shape=(seq_arr.shape[1],), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], \n",
    "                             embedding_matrix.shape[1],\n",
    "                             weights = [embedding_matrix],\n",
    "                             name = 'embedding')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(2)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(1)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "# l_pool3 = MaxPooling1D(2)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_cov3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "l_dense = Dropout(0.5)(l_dense)\n",
    "preds = Dense(1, activation='sigmoid')(l_dense)\n",
    "                          \n",
    "model = Model(inputs = [sequence_input], output = [preds])\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), loss = losses.binary_crossentropy,\n",
    "              metrics = [metrics.binary_crossentropy, metrics.binary_accuracy,\n",
    "                         f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 659437 samples, validate on 439626 samples\n",
      "Epoch 1/25\n",
      "659437/659437 [==============================] - 25s 38us/step - loss: 0.1372 - binary_crossentropy: 0.1372 - binary_accuracy: 0.9512 - f1: 0.3988 - val_loss: 0.1104 - val_binary_crossentropy: 0.1104 - val_binary_accuracy: 0.9567 - val_f1: 0.5412\n",
      "Epoch 2/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0991 - binary_crossentropy: 0.0991 - binary_accuracy: 0.9607 - f1: 0.6110 - val_loss: 0.1085 - val_binary_crossentropy: 0.1085 - val_binary_accuracy: 0.9575 - val_f1: 0.5695\n",
      "Epoch 3/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0832 - binary_crossentropy: 0.0832 - binary_accuracy: 0.9661 - f1: 0.6820 - val_loss: 0.1146 - val_binary_crossentropy: 0.1146 - val_binary_accuracy: 0.9560 - val_f1: 0.5862\n",
      "Epoch 4/25\n",
      "659437/659437 [==============================] - 23s 35us/step - loss: 0.0632 - binary_crossentropy: 0.0632 - binary_accuracy: 0.9742 - f1: 0.7668 - val_loss: 0.1516 - val_binary_crossentropy: 0.1516 - val_binary_accuracy: 0.9530 - val_f1: 0.5784\n",
      "Epoch 5/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0422 - binary_crossentropy: 0.0422 - binary_accuracy: 0.9832 - f1: 0.8503 - val_loss: 0.2066 - val_binary_crossentropy: 0.2066 - val_binary_accuracy: 0.9525 - val_f1: 0.5504\n",
      "Epoch 6/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0266 - binary_crossentropy: 0.0266 - binary_accuracy: 0.9896 - f1: 0.9067 - val_loss: 0.2388 - val_binary_crossentropy: 0.2388 - val_binary_accuracy: 0.9488 - val_f1: 0.5219\n",
      "Epoch 7/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0163 - binary_crossentropy: 0.0163 - binary_accuracy: 0.9938 - f1: 0.9444 - val_loss: 0.2920 - val_binary_crossentropy: 0.2920 - val_binary_accuracy: 0.9482 - val_f1: 0.5386\n",
      "Epoch 8/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0113 - binary_crossentropy: 0.0113 - binary_accuracy: 0.9958 - f1: 0.9627 - val_loss: 0.3290 - val_binary_crossentropy: 0.3290 - val_binary_accuracy: 0.9497 - val_f1: 0.5250\n",
      "Epoch 9/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0086 - binary_crossentropy: 0.0086 - binary_accuracy: 0.9969 - f1: 0.9721 - val_loss: 0.3624 - val_binary_crossentropy: 0.3624 - val_binary_accuracy: 0.9505 - val_f1: 0.5003\n",
      "Epoch 10/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0068 - binary_crossentropy: 0.0068 - binary_accuracy: 0.9976 - f1: 0.9787 - val_loss: 0.3959 - val_binary_crossentropy: 0.3959 - val_binary_accuracy: 0.9508 - val_f1: 0.5027\n",
      "Epoch 11/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0054 - binary_crossentropy: 0.0054 - binary_accuracy: 0.9981 - f1: 0.9833 - val_loss: 0.3917 - val_binary_crossentropy: 0.3917 - val_binary_accuracy: 0.9494 - val_f1: 0.5044\n",
      "Epoch 12/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0048 - binary_crossentropy: 0.0048 - binary_accuracy: 0.9983 - f1: 0.9852 - val_loss: 0.3907 - val_binary_crossentropy: 0.3907 - val_binary_accuracy: 0.9485 - val_f1: 0.5073\n",
      "Epoch 13/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0042 - binary_crossentropy: 0.0042 - binary_accuracy: 0.9985 - f1: 0.9869 - val_loss: 0.4256 - val_binary_crossentropy: 0.4256 - val_binary_accuracy: 0.9481 - val_f1: 0.5289\n",
      "Epoch 14/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0041 - binary_crossentropy: 0.0041 - binary_accuracy: 0.9986 - f1: 0.9872 - val_loss: 0.4248 - val_binary_crossentropy: 0.4248 - val_binary_accuracy: 0.9489 - val_f1: 0.5241\n",
      "Epoch 15/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0037 - binary_crossentropy: 0.0037 - binary_accuracy: 0.9987 - f1: 0.9881 - val_loss: 0.4428 - val_binary_crossentropy: 0.4428 - val_binary_accuracy: 0.9487 - val_f1: 0.5034\n",
      "Epoch 16/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0039 - binary_crossentropy: 0.0039 - binary_accuracy: 0.9987 - f1: 0.9884 - val_loss: 0.4048 - val_binary_crossentropy: 0.4048 - val_binary_accuracy: 0.9487 - val_f1: 0.5011\n",
      "Epoch 17/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0032 - binary_crossentropy: 0.0032 - binary_accuracy: 0.9989 - f1: 0.9904 - val_loss: 0.4387 - val_binary_crossentropy: 0.4387 - val_binary_accuracy: 0.9506 - val_f1: 0.5152\n",
      "Epoch 18/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0031 - binary_crossentropy: 0.0031 - binary_accuracy: 0.9990 - f1: 0.9910 - val_loss: 0.4450 - val_binary_crossentropy: 0.4450 - val_binary_accuracy: 0.9479 - val_f1: 0.5273\n",
      "Epoch 19/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0025 - binary_crossentropy: 0.0025 - binary_accuracy: 0.9992 - f1: 0.9926 - val_loss: 0.4406 - val_binary_crossentropy: 0.4406 - val_binary_accuracy: 0.9476 - val_f1: 0.5146\n",
      "Epoch 20/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0028 - binary_crossentropy: 0.0028 - binary_accuracy: 0.9991 - f1: 0.9919 - val_loss: 0.4384 - val_binary_crossentropy: 0.4384 - val_binary_accuracy: 0.9496 - val_f1: 0.5098\n",
      "Epoch 21/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0027 - binary_crossentropy: 0.0027 - binary_accuracy: 0.9991 - f1: 0.9918 - val_loss: 0.4531 - val_binary_crossentropy: 0.4531 - val_binary_accuracy: 0.9504 - val_f1: 0.5243\n",
      "Epoch 22/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0026 - binary_crossentropy: 0.0026 - binary_accuracy: 0.9991 - f1: 0.9922 - val_loss: 0.4608 - val_binary_crossentropy: 0.4608 - val_binary_accuracy: 0.9491 - val_f1: 0.4991\n",
      "Epoch 23/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0023 - binary_crossentropy: 0.0023 - binary_accuracy: 0.9992 - f1: 0.9931 - val_loss: 0.4555 - val_binary_crossentropy: 0.4555 - val_binary_accuracy: 0.9494 - val_f1: 0.5198\n",
      "Epoch 24/25\n",
      "659437/659437 [==============================] - 23s 34us/step - loss: 0.0022 - binary_crossentropy: 0.0022 - binary_accuracy: 0.9993 - f1: 0.9934 - val_loss: 0.4465 - val_binary_crossentropy: 0.4465 - val_binary_accuracy: 0.9517 - val_f1: 0.4887\n",
      "Epoch 25/25\n",
      "510976/659437 [======================>.......] - ETA: 4s - loss: 0.0019 - binary_crossentropy: 0.0019 - binary_accuracy: 0.9994 - f1: 0.9947"
     ]
    }
   ],
   "source": [
    "history = model.fit(seq_arr, labels, validation_split = 0.4,\n",
    "                    epochs = 25, batch_size = 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = datadir + 'glove.840B.300d/glove.840B.300d.txt'\n",
    "def get_coefs(word,*arr): \n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_embs = np.stack(embeddings_index.values())\n",
    "emb_mean,emb_std = all_embs.mean(), all_embs.std()\n",
    "embed_size = all_embs.shape[1]\n",
    "\n",
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (vs, embed_size))\n",
    "\n",
    "print('Embedding Matrix Shape: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "from timeit import default_timer as timer\n",
    "pool = Pool(15)\n",
    "\n",
    "def get_embed_vector(word):\n",
    "    return embeddings_index.get(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = word_index.keys()\n",
    "r = pool.map(get_embed_vector, words)\n",
    "pool.close()\n",
    "pool.join()\n",
    "\n",
    "# not_in = 0\n",
    "# for word, i in word_index.items():\n",
    "#     embedding_vector = embeddings_index.get(word)\n",
    "#     if embedding_vector is not None: \n",
    "#         embedding_matrix[i] = embedding_vector\n",
    "#     else:\n",
    "#         not_in += 1\n",
    "\n",
    "# print('There were ', not_in 'words not in the embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.normal(emb_mean, emb_std, (vs, embed_size))\n",
    "\n",
    "print('Embedding Matrix Shape: ', embedding_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.array(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found = 0\n",
    "for a in arr:\n",
    "    if a is not None:\n",
    "        continue\n",
    "    else:\n",
    "        not_found += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "not_found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.random.normal(size = (vs, 300))\n",
    "for i, a in enumerate(arr):\n",
    "    if a is not None:\n",
    "        embedding_matrix[i] = a\n",
    "    else:\n",
    "        continue\n",
    "        \n",
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('glove_embeddings.npy', embedding_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in r:\n",
    "    if i == None:\n",
    "        print('Found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.mean(r == None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('word_index.json', 'w') as f:\n",
    "    f.write(json.dumps(word_index))\n",
    "    \n",
    "with open('index_word.json', 'w') as f:\n",
    "    f.write(json.dumps(index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences, labels, test_sequences, word_index, index_word, wc, vs = format_data(train_df, test_df,\n",
    "                                                                            filters = '')\n",
    "print('Shape of data: ', sequences.shape)\n",
    "print('Shape of labels: ', labels.shape)\n",
    "print('Number of words in vocab: ', vs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sequence_to_query(sequence, index_word):\n",
    "    query = [index_word.get(i, 'UNK') for i in sequence]\n",
    "    return ' '.join(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_to_query(sequences[15], index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_embeddings = np.load('fasttext_embeddings.npy')\n",
    "# fasttext_embeddings = normalize(fasttext_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
