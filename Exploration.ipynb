{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['/device:GPU:0', '/device:GPU:1']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from utils import f1\n",
    "from keras import callbacks\n",
    "from timeit import default_timer as timer\n",
    "from keras import models, losses, metrics, layers, optimizers\n",
    "from keras.utils import multi_gpu_model\n",
    "import tensorflow as tf\n",
    "import re\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import os\n",
    "import keras\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = 'all'\n",
    "\n",
    "\n",
    "def get_available_gpus():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos if x.device_type == 'GPU']\n",
    "\n",
    "\n",
    "get_available_gpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paragram_300_sl999 ['README.txt', 'paragram_300_sl999.txt']\n",
      "GoogleNews-vectors-negative300 ['GoogleNews-vectors-negative300.bin']\n",
      "wiki-news-300d-1M ['wiki-news-300d-1M.vec']\n",
      "sample_submission.csv\n",
      "train.csv\n",
      "test.csv\n",
      "glove.840B.300d ['glove.840B.300d.txt']\n",
      "models ['wt103']\n"
     ]
    }
   ],
   "source": [
    "datadir = '/home/wjk68/data/quora/'\n",
    "\n",
    "for d in os.listdir(datadir):\n",
    "    if os.path.isdir(datadir + d):\n",
    "        print(d, os.listdir(datadir + d))\n",
    "    else:\n",
    "        print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>question_text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>How did Quebec nationalists see their province...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Do you have an adopted dog, how would you enco...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Why does velocity affect time? Does velocity a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       question_text  target\n",
       "0  How did Quebec nationalists see their province...       0\n",
       "1  Do you have an adopted dog, how would you enco...       0\n",
       "2  Why does velocity affect time? Does velocity a...       0\n",
       "3  How did Otto von Guericke used the Magdeburg h...       0\n",
       "4  Can I convert montra helicon D to a mountain b...       0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(datadir + 'train.csv', usecols=[1, 2])\n",
    "test = pd.read_csv(datadir + 'test.csv', usecols=[0, 1])\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    1.306122e+06\n",
       "mean     7.067884e+01\n",
       "std      3.878428e+01\n",
       "min      1.000000e+00\n",
       "25%      4.500000e+01\n",
       "50%      6.000000e+01\n",
       "75%      8.500000e+01\n",
       "max      1.017000e+03\n",
       "Name: length, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['length'] = [len(q) for q in train['question_text']]\n",
    "train['length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x7fcf9fb33da0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "g = sns.FacetGrid(hue = 'target', data = train)\n",
    "g.map(sns.kdeplot, 'length')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(x = 'target', y = 'length', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf8c66ecc0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train['question_text'])\n",
    "s = tokenizer.texts_to_sequences(train['question_text'])\n",
    "lens = [len(i) for i in s]\n",
    "train['n_words'] = lens\n",
    "sns.boxplot(x = 'target', y = 'n_words', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf79c57470>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = Tokenizer(filters = '')\n",
    "tokenizer.fit_on_texts(train['question_text'])\n",
    "s2 = tokenizer.texts_to_sequences(train['question_text'])\n",
    "lens = [len(i) for i in s2]\n",
    "train['n_words_2'] = lens\n",
    "sns.boxplot(x = 'target', y = 'n_words_2', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fcf6950e7b8>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['diff'] = train['n_words']  - train['n_words_2']\n",
    "sns.boxplot(x = 'target', y = 'diff', data = train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train['chars_per'] = train['length'] / train['n_words']\n",
    "sns.boxplot(x = 'target', y = 'chars_per', data = train);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target</th>\n",
       "      <th>length</th>\n",
       "      <th>n_words</th>\n",
       "      <th>n_words_2</th>\n",
       "      <th>diff</th>\n",
       "      <th>chars_per</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>target</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.181331</td>\n",
       "      <td>0.162895</td>\n",
       "      <td>0.162835</td>\n",
       "      <td>0.020163</td>\n",
       "      <td>0.037365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>length</th>\n",
       "      <td>0.181331</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.969009</td>\n",
       "      <td>0.967383</td>\n",
       "      <td>0.135612</td>\n",
       "      <td>0.097550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_words</th>\n",
       "      <td>0.162895</td>\n",
       "      <td>0.969009</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>0.158772</td>\n",
       "      <td>-0.119783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>n_words_2</th>\n",
       "      <td>0.162835</td>\n",
       "      <td>0.967383</td>\n",
       "      <td>0.996797</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>-0.115075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diff</th>\n",
       "      <td>0.020163</td>\n",
       "      <td>0.135612</td>\n",
       "      <td>0.158772</td>\n",
       "      <td>0.079306</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.072406</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>chars_per</th>\n",
       "      <td>0.037365</td>\n",
       "      <td>0.097550</td>\n",
       "      <td>-0.119783</td>\n",
       "      <td>-0.115075</td>\n",
       "      <td>-0.072406</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             target    length   n_words  n_words_2      diff  chars_per\n",
       "target     1.000000  0.181331  0.162895   0.162835  0.020163   0.037365\n",
       "length     0.181331  1.000000  0.969009   0.967383  0.135612   0.097550\n",
       "n_words    0.162895  0.969009  1.000000   0.996797  0.158772  -0.119783\n",
       "n_words_2  0.162835  0.967383  0.996797   1.000000  0.079306  -0.115075\n",
       "diff       0.020163  0.135612  0.158772   0.079306  1.000000  -0.072406\n",
       "chars_per  0.037365  0.097550 -0.119783  -0.115075 -0.072406   1.000000"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs  = train.corr()\n",
    "corrs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = 'this is a string with spaces'\n",
    "import re\n",
    "re.sub('\\s', '', s)\n",
    "texts = [re.sub('\\s', '', s) for s in train['question_text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1306122x100 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 27733474 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from timeit import default_timer as timer\n",
    "\n",
    "start = timer()\n",
    "vectorizer = CountVectorizer(lowercase = False, analyzer = 'char', \n",
    "                             max_features = 100)\n",
    "X = vectorizer.fit_transform(texts)\n",
    "end = timer()\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 100)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr = X.toarray()\n",
    "X_arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]], dtype=int64)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>!</th>\n",
       "      <th>\"</th>\n",
       "      <th>#</th>\n",
       "      <th>$</th>\n",
       "      <th>%</th>\n",
       "      <th>&amp;</th>\n",
       "      <th>'</th>\n",
       "      <th>(</th>\n",
       "      <th>)</th>\n",
       "      <th>*</th>\n",
       "      <th>...</th>\n",
       "      <th>}</th>\n",
       "      <th>é</th>\n",
       "      <th>ा</th>\n",
       "      <th>​</th>\n",
       "      <th>‘</th>\n",
       "      <th>’</th>\n",
       "      <th>“</th>\n",
       "      <th>”</th>\n",
       "      <th>…</th>\n",
       "      <th>√</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   !  \"  #  $  %  &  '  (  )  * ...  }  é  ा  ​  ‘  ’  “  ”  …  √\n",
       "0  0  0  0  0  0  0  0  0  0  0 ...  0  0  0  0  0  0  0  0  0  0\n",
       "1  0  0  0  0  0  0  0  0  0  0 ...  0  0  0  0  0  0  0  0  0  0\n",
       "2  0  0  0  0  0  0  0  0  0  0 ...  0  0  0  0  0  0  0  0  0  0\n",
       "3  0  0  0  0  0  0  0  0  0  0 ...  0  0  0  0  0  0  0  0  0  0\n",
       "4  0  0  0  0  0  0  0  0  0  0 ...  0  0  0  0  0  0  0  0  0  0\n",
       "\n",
       "[5 rows x 100 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_counts = pd.DataFrame(X_arr)\n",
    "df_counts.columns = vectorizer.get_feature_names()\n",
    "df_counts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['!',\n",
       " '\"',\n",
       " '#',\n",
       " '$',\n",
       " '%',\n",
       " '&',\n",
       " \"'\",\n",
       " '(',\n",
       " ')',\n",
       " '*',\n",
       " '+',\n",
       " ',',\n",
       " '-',\n",
       " '.',\n",
       " '/',\n",
       " '0',\n",
       " '1',\n",
       " '2',\n",
       " '3',\n",
       " '4',\n",
       " '5',\n",
       " '6',\n",
       " '7',\n",
       " '8',\n",
       " '9',\n",
       " ':',\n",
       " ';',\n",
       " '<',\n",
       " '=',\n",
       " '>',\n",
       " '?',\n",
       " 'A',\n",
       " 'B',\n",
       " 'C',\n",
       " 'D',\n",
       " 'E',\n",
       " 'F',\n",
       " 'G',\n",
       " 'H',\n",
       " 'I',\n",
       " 'J',\n",
       " 'K',\n",
       " 'L',\n",
       " 'M',\n",
       " 'N',\n",
       " 'O',\n",
       " 'P',\n",
       " 'Q',\n",
       " 'R',\n",
       " 'S',\n",
       " 'T',\n",
       " 'U',\n",
       " 'V',\n",
       " 'W',\n",
       " 'X',\n",
       " 'Y',\n",
       " 'Z',\n",
       " '[',\n",
       " '\\\\',\n",
       " ']',\n",
       " '^',\n",
       " '_',\n",
       " 'a',\n",
       " 'b',\n",
       " 'c',\n",
       " 'd',\n",
       " 'e',\n",
       " 'f',\n",
       " 'g',\n",
       " 'h',\n",
       " 'i',\n",
       " 'j',\n",
       " 'k',\n",
       " 'l',\n",
       " 'm',\n",
       " 'n',\n",
       " 'o',\n",
       " 'p',\n",
       " 'q',\n",
       " 'r',\n",
       " 's',\n",
       " 't',\n",
       " 'u',\n",
       " 'v',\n",
       " 'w',\n",
       " 'x',\n",
       " 'y',\n",
       " 'z',\n",
       " '{',\n",
       " '|',\n",
       " '}',\n",
       " 'é',\n",
       " 'ा',\n",
       " '\\u200b',\n",
       " '‘',\n",
       " '’',\n",
       " '“',\n",
       " '”',\n",
       " '…',\n",
       " '√']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "target       1.000000\n",
       "length       0.181331\n",
       "n_words      0.162895\n",
       "n_words_2    0.162835\n",
       "diff         0.020163\n",
       "chars_per    0.037365\n",
       "!            0.031410\n",
       "\"            0.024399\n",
       "#            0.004229\n",
       "$           -0.001863\n",
       "%            0.006405\n",
       "&            0.013174\n",
       "'            0.063044\n",
       "(            0.004874\n",
       ")            0.005141\n",
       "*            0.012785\n",
       "+           -0.010186\n",
       ",            0.117177\n",
       "-            0.046527\n",
       ".            0.048505\n",
       "/            0.000358\n",
       "0           -0.013187\n",
       "1           -0.016200\n",
       "2           -0.020039\n",
       "3           -0.012231\n",
       "4           -0.008893\n",
       "5           -0.011110\n",
       "6           -0.006319\n",
       "7           -0.013567\n",
       "8           -0.011078\n",
       "               ...   \n",
       "i            0.155575\n",
       "j            0.030171\n",
       "k            0.077828\n",
       "l            0.158930\n",
       "m            0.120216\n",
       "n            0.143459\n",
       "o            0.109432\n",
       "p            0.092348\n",
       "q            0.009401\n",
       "r            0.131427\n",
       "s            0.173433\n",
       "t            0.134379\n",
       "u            0.104839\n",
       "v            0.063802\n",
       "w            0.079395\n",
       "x            0.022331\n",
       "y            0.141117\n",
       "z            0.034725\n",
       "{            0.003863\n",
       "|           -0.002154\n",
       "}            0.003919\n",
       "é           -0.002128\n",
       "ा           -0.001452\n",
       "​           -0.003228\n",
       "‘            0.026775\n",
       "’            0.070468\n",
       "“            0.041486\n",
       "”            0.041471\n",
       "…            0.014309\n",
       "√           -0.002888\n",
       "Name: target, Length: 106, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = pd.concat([train, df_counts], axis = 1)\n",
    "corrs = df_train.corr()\n",
    "corrs['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "H           -0.032506\n",
       "2           -0.020039\n",
       "1           -0.016200\n",
       "7           -0.013567\n",
       "0           -0.013187\n",
       "3           -0.012231\n",
       "5           -0.011110\n",
       "8           -0.011078\n",
       "+           -0.010186\n",
       "4           -0.008893\n",
       "V           -0.007495\n",
       "X           -0.007151\n",
       "6           -0.006319\n",
       "=           -0.005873\n",
       "​           -0.003228\n",
       "√           -0.002888\n",
       "^           -0.002881\n",
       "|           -0.002154\n",
       "é           -0.002128\n",
       "$           -0.001863\n",
       ">           -0.001658\n",
       "<           -0.001651\n",
       "ा           -0.001452\n",
       "/            0.000358\n",
       "_            0.000427\n",
       "9            0.000719\n",
       "F            0.000738\n",
       "[            0.001071\n",
       "]            0.001845\n",
       "E            0.002346\n",
       "               ...   \n",
       "'            0.063044\n",
       "v            0.063802\n",
       "Q            0.069074\n",
       "’            0.070468\n",
       "g            0.071612\n",
       "?            0.072250\n",
       "k            0.077828\n",
       "A            0.079365\n",
       "w            0.079395\n",
       "b            0.081391\n",
       "p            0.092348\n",
       "u            0.104839\n",
       "o            0.109432\n",
       ",            0.117177\n",
       "m            0.120216\n",
       "d            0.122443\n",
       "r            0.131427\n",
       "t            0.134379\n",
       "a            0.141108\n",
       "y            0.141117\n",
       "n            0.143459\n",
       "e            0.151905\n",
       "i            0.155575\n",
       "h            0.158466\n",
       "l            0.158930\n",
       "n_words_2    0.162835\n",
       "n_words      0.162895\n",
       "s            0.173433\n",
       "length       0.181331\n",
       "target       1.000000\n",
       "Name: target, Length: 106, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs['target'].sort_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "tokenizer = Tokenizer(filters = '', char_level=True, lower = False)\n",
    "tokenizer.fit_on_texts(texts)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = tokenizer.texts_to_sequences(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2045"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nchars = len(tokenizer.word_counts) + 1\n",
    "nchars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306122"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1306122, 973)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "lens = [len(c) for c in chars]\n",
    "chars = pad_sequences(chars, max(lens))\n",
    "chars = np.array(chars, dtype = int)\n",
    "chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59728"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def retrieve_saved_data():\n",
    "    \"\"\"Retrieve already formatted data\"\"\"\n",
    "    \n",
    "    sequences = np.load('sequences.npy')\n",
    "    test_sequences = np.load('test_sequences.npy')\n",
    "    labels = np.load('labels.npy')\n",
    "    \n",
    "    iw = []\n",
    "    with open('index_word.json', 'r') as f:\n",
    "        for l in f:\n",
    "            iw.append(json.loads(l))\n",
    "\n",
    "    index_word = iw[0]\n",
    "    index_word = {int(key): word for key, word in index_word.items()}\n",
    "\n",
    "    wi = []\n",
    "    with open('word_index.json', 'r') as f:\n",
    "        for l in f:\n",
    "            wi.append(json.loads(l))\n",
    "\n",
    "    word_index = wi[0]\n",
    "    word_index = {word: int(index) for word, index in word_index.items()}\n",
    "    \n",
    "    vs = len(word_index) + 1\n",
    "    \n",
    "    return sequences, labels, test_sequences, word_index, index_word, vs\n",
    "\n",
    "sequences, labels, test_sequences, word_index, index_word, vs = retrieve_saved_data()\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(973), Dimension(100)])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedded_chars.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = pad_sequences(sequences, chars.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([Dimension(None), Dimension(64)])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seq_lstm.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('cpu/:0'):\n",
    "    \n",
    "    sequence_input = Input(shape = (sequences.shape[1],), dtype = 'int32')\n",
    "    char_input = Input(shape = (chars.shape[1],), dtype = 'int32')\n",
    "\n",
    "    sequence_embedding = Embedding(vs, 100, name = 'sequence_embedding')\n",
    "    embedded_sequences = sequence_embedding(sequence_input)\n",
    "    seq_lstm = CuDNNLSTM(64, name = 'seq_lstm')(embedded_sequences)\n",
    "\n",
    "    char_embedding = Embedding(nchars, 100, name = 'char_embedding')\n",
    "    embedded_chars = char_embedding(char_input)\n",
    "    char_lstm = CuDNNLSTM(64, name = 'char_lstm')(embedded_chars)\n",
    "\n",
    "    combined = Concatenate()([seq_lstm, char_lstm])\n",
    "\n",
    "    fc1 = Dense(128, activation = 'relu')(combined)\n",
    "    fc1 = Dropout(0.5)(fc1)\n",
    "    fc2 = Dense(64, activation = 'relu')(fc1)\n",
    "    fc2 = Dropout(0.5)(fc2)\n",
    "    out = Dense(1, activation = 'sigmoid')(fc2)\n",
    "\n",
    "    model = Model(inputs = [sequence_input, char_input], outputs = [out])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_11 (InputLayer)           (None, 492)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_12 (InputLayer)           (None, 973)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sequence_embedding (Embedding)  (None, 492, 100)     5972800     input_11[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "char_embedding (Embedding)      (None, 973, 100)     204500      input_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "seq_lstm (CuDNNLSTM)            (None, 64)           42496       sequence_embedding[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "char_lstm (CuDNNLSTM)           (None, 64)           42496       char_embedding[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_6 (Concatenate)     (None, 128)          0           seq_lstm[0][0]                   \n",
      "                                                                 char_lstm[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_7 (Dense)                 (None, 128)          16512       concatenate_6[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 128)          0           dense_7[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_8 (Dense)                 (None, 64)           8256        dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_6 (Dropout)             (None, 64)           0           dense_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_9 (Dense)                 (None, 1)            65          dropout_6[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 6,287,125\n",
      "Trainable params: 6,287,125\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils import * \n",
    "model = multi_gpu_model(model, gpus = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer = optimizers.Adam(), loss = losses.binary_crossentropy, \n",
    "              metrics = [metrics.binary_accuracy, metrics.binary_crossentropy, f1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/2\n",
      "914285/914285 [==============================] - 511s 559us/step - loss: 0.1386 - binary_accuracy: 0.9505 - binary_crossentropy: 0.1386 - val_loss: 0.1133 - val_binary_accuracy: 0.9549 - val_binary_crossentropy: 0.1133\n",
      "Epoch 2/2\n",
      "914285/914285 [==============================] - 397s 434us/step - loss: 0.1047 - binary_accuracy: 0.9587 - binary_crossentropy: 0.1047 - val_loss: 0.1140 - val_binary_accuracy: 0.9527 - val_binary_crossentropy: 0.1140\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fcf7a1ecac8>"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit([sequences, chars], labels, epochs = 2, batch_size = 1024,\n",
    "          validation_split = 0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/12\n",
      "  7168/914285 [..............................] - ETA: 8:12 - loss: 0.0899 - binary_accuracy: 0.9633 - binary_crossentropy: 0.0899 - f1: 0.6952"
     ]
    }
   ],
   "source": [
    "model_name = 'combined'\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(monitor='val_loss', patience=3),\n",
    "                     callbacks.ModelCheckpoint(filepath=f'models/{model_name}.h5',\n",
    "                                               save_best_only=True, save_weights_only=True)]\n",
    "\n",
    "model.fit([sequences, chars], labels, epochs = 12, batch_size = 1024,\n",
    "          validation_split = 0.3, callbacks=callback_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1306122"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "embeddings_words = Embedding(vs, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "re.compile(r'[A-Z]', re.UNICODE)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "cap = re.compile(r'[A-Z]')\n",
    "cap"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "lens[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Was 2016 the worst year for cheaters? Hillary cheated Bernie, and Russia tried to dirty Hillary's reputation because they knew she was going to win.\",\n",
       " 'Can humans and sheep produce offspring?',\n",
       " 'How did Donald J. Trump become a psychopath? He seem to care about his money more than anything on this planet.',\n",
       " 'How can I download the Blue Whale Challenge original game?',\n",
       " 'Why the Pakistani media and Pakistani people gave no importance to the statements of Indian media and Indian people?',\n",
       " 'Is using the word “Nazi” instead of “NSDAP” a sign you are brainwashed?',\n",
       " 'What do Sri Lankan girls think about Bangladeshi guys in terms of dating and marriage?',\n",
       " \"What was the major embarrassment of 2017: caste, corruption, Modi's painful acronyms or Venkaiah Naidu's worshiping statements?\",\n",
       " \"Instead of embarrassing the US, why doesn't Donald Trump realise the 1st rule for holding a position of that magnitude? Keep your mouth shut. If he’s smart enough to get the President’s job, he knows his words aren’t the same as an ordinary American.\",\n",
       " 'Why are there so many weird people on here asking weird questions?']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.options.display.max_colwidth = 200\n",
    "list(train.loc[train['target'] == 1, 'question_text'].sample(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_sequence(s):\n",
    "    \"\"\"Add spaces around punctuation.\"\"\"\n",
    "\n",
    "    # Add spaces around punctuation\n",
    "    s = re.sub(\n",
    "        r'(?<=[^\\s])(?=[“”!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~\\t\\n])|(?=[^\\s])(?<=[“”!\\\"#$%&()*+,./:;<=>?@[\\]^_`{|}~\\t\\n])', r' ', s)\n",
    "\n",
    "    # Remove double spaces\n",
    "    s = re.sub(r'\\s\\s', ' ', s)\n",
    "    return s\n",
    "\n",
    "\n",
    "def format_data(df_train, df_test,\n",
    "                filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n',\n",
    "                keep_freq=5):\n",
    "    \"\"\"Format text data\"\"\"\n",
    "    texts = list(df_train['question_text'])\n",
    "    texts = [format_sequence(t) for t in texts]\n",
    "\n",
    "    # Fit once to get word counts\n",
    "    tokenizer = Tokenizer(lower=False, filters=filters)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    wc = tokenizer.word_counts\n",
    "    wc = sorted(wc.items(), key=lambda x: x[1], reverse=True)\n",
    "    keep = [w for w in wc if w[1] >= keep_freq]\n",
    "\n",
    "    # Create again to limit to top words\n",
    "    tokenizer = Tokenizer(num_words=len(keep),\n",
    "                          lower=False,\n",
    "                          filters=filters)\n",
    "    tokenizer.fit_on_texts(texts)\n",
    "    word_index = dict(list(tokenizer.word_index.items())[:len(keep)])\n",
    "    index_word = dict(list(tokenizer.index_word.items())[:len(keep)])\n",
    "    wc = tokenizer.word_counts\n",
    "    wc = sorted(wc.items(), key=lambda x: x[1], reverse=True)[:len(keep)]\n",
    "\n",
    "    sequences = tokenizer.texts_to_sequences(texts)\n",
    "    lens = [len(s) for s in sequences]\n",
    "    \n",
    "    vs = tokenizer.num_words + 1\n",
    "\n",
    "    # Pad sequences to have same length\n",
    "    sequences = pad_sequences(sequences, max(lens))\n",
    "    sequences = np.array(sequences, dtype=int)\n",
    "\n",
    "    # Labels\n",
    "    labels = np.array(df_train['target'], dtype=int)\n",
    "\n",
    "    # Test data\n",
    "    test_texts = list(df_test['question_text'])\n",
    "    test_texts = [format_sequence(t) for t in test_texts]\n",
    "    test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "    test_sequences = pad_sequences(test_sequences, max(lens))\n",
    "    test_sequences = np.array(test_sequences, dtype=int)\n",
    "\n",
    "    return sequences, labels, test_sequences, word_index, index_word, wc, vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 59728 words in the vocab.\n",
      "There are 59727 words in the vocab.\n"
     ]
    }
   ],
   "source": [
    "filters = ''\n",
    "sequences, labels, test_sequences, word_index, index_word, wc, vs = format_data(train, test,\n",
    "                                                                            filters=filters, keep_freq=5)\n",
    "print(f'There are {vs} words in the vocab.')\n",
    "print(f'There are {len(word_index)} words in the vocab.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('sequences.npy', sequences)\n",
    "np.save('test_sequences.npy', test_sequences)\n",
    "np.save('labels.npy', labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1068885"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "with open('word_index.json', 'w') as f:\n",
    "    f.write(json.dumps(word_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1188339"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('index_word.json', 'w') as f:\n",
    "    f.write(json.dumps(index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_saved_data():\n",
    "    \"\"\"Retrieve already formatted data\"\"\"\n",
    "    \n",
    "    sequences = np.load('sequences.npy')\n",
    "    test_sequences = np.load('test_sequences.npy')\n",
    "    labels = np.load('labels.npy')\n",
    "    \n",
    "    iw = []\n",
    "    with open('index_word.json', 'r') as f:\n",
    "        for l in f:\n",
    "            iw.append(json.loads(l))\n",
    "\n",
    "    index_word = iw[0]\n",
    "    index_word = {int(key): word for key, word in index_word.items()}\n",
    "\n",
    "    wi = []\n",
    "    with open('word_index.json', 'r') as f:\n",
    "        for l in f:\n",
    "            wi.append(json.loads(l))\n",
    "\n",
    "    word_index = wi[0]\n",
    "    word_index = {word: int(index) for word, index in word_index.items()}\n",
    "    \n",
    "    vs = len(word_index) + 1\n",
    "    \n",
    "    return sequences, labels, test_sequences, word_index, index_word, vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "59728"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sequences, labels, test_sequences, word_index, index_word, vs = retrieve_saved_data()\n",
    "vs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_gpu = len(get_available_gpus()) > 1\n",
    "\n",
    "def get_model(vs, model_name, lstm_layer, embeddings = None):\n",
    "\n",
    "    if multi_gpu:\n",
    "        device = '/cpu:0'\n",
    "    else:\n",
    "        device = '/gpu:0'\n",
    "\n",
    "    with tf.device(device):\n",
    "        model = models.Sequential()\n",
    "        if embeddings is not None:\n",
    "            model.add(layers.Embedding(vs, embeddings.shape[1], \n",
    "                                       weights = [embeddings]))\n",
    "        else:\n",
    "            model.add(layers.Embedding(vs, 50))\n",
    "            \n",
    "        # model.add(layers.Masking(mask_value = 0.))\n",
    "        model.add(layers.Bidirectional(lstm_layer))\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(32, activation='relu'))\n",
    "        model.add(layers.Dropout(0.5))\n",
    "        model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "    if multi_gpu:\n",
    "        model = multi_gpu_model(model, gpus=len(get_available_gpus()))\n",
    "\n",
    "    model.compile(optimizer=optimizers.Adam(),\n",
    "                  loss=losses.binary_crossentropy,\n",
    "                  metrics=[metrics.binary_accuracy,  metrics.binary_crossentropy, f1])\n",
    "\n",
    "    callback_list = [callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "                     callbacks.ModelCheckpoint(filepath=f'models/{model_name}.h5',\n",
    "                                               save_best_only=True, save_weights_only=False)]\n",
    "\n",
    "    model.callbacks = callback_list\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-51-737416848935>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cudnn_model_severe'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCuDNNLSTM\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_sequences\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-c82343bf2553>\u001b[0m in \u001b[0;36mget_model\u001b[0;34m(vs, model_name, lstm_layer, embeddings)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_gpu\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmulti_gpu_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_available_gpus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m     model.compile(optimizer=optimizers.Adam(),\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36mmulti_gpu_model\u001b[0;34m(model, gpus, cpu_merge, cpu_relocation)\u001b[0m\n\u001b[1;32m    145\u001b[0m                          'with the TensorFlow backend.')\n\u001b[1;32m    146\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m     \u001b[0mavailable_devices\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_available_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    148\u001b[0m     available_devices = [_normalize_device_name(name)\n\u001b[1;32m    149\u001b[0m                          for name in available_devices]\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/utils/multi_gpu_utils.py\u001b[0m in \u001b[0;36m_get_available_devices\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_get_available_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlist_devices\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 197\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "model = get_model(vs, 'cudnn_model_severe', layers.CuDNNLSTM(64, return_sequences = False))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/2\n"
     ]
    },
    {
     "ename": "InternalError",
     "evalue": "GPU sync failed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mInternalError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-52-15295f5c295f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m history = model.fit(sequences, labels, callbacks=model.callbacks,\n\u001b[1;32m      3\u001b[0m                     \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                     batch_size=8192, verbose = 1)\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtimer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'\\nCuDNN LSTM model took {end - start:.2f} seconds.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1035\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1037\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1038\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1039\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2658\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_make_callable_from_options'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2659\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_sparse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2660\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/gcc-6_3_0/openmpi-2_0_1/python/3.6.6/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m()\u001b[0m\n\u001b[1;32m    195\u001b[0m                 \u001b[0;31m# not already marked as initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m                 is_initialized = session.run(\n\u001b[0;32m--> 197\u001b[0;31m                     [tf.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    198\u001b[0m                 \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0mflag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcandidate_vars\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1346\u001b[0m           \u001b[0;32mpass\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0merror_interpolation\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minterpolate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1350\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mInternalError\u001b[0m: GPU sync failed"
     ]
    }
   ],
   "source": [
    "start = timer()\n",
    "history = model.fit(sequences, labels, callbacks=model.callbacks,\n",
    "                    epochs = 2, validation_split = 0.3,\n",
    "                    batch_size=8192, verbose = 1)\n",
    "end = timer()\n",
    "print(f'\\nCuDNN LSTM model took {end - start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('models/cudnn_model_severe.h5', custom_objects = {'f1': f1})\n",
    "weights = model.get_layer(index = 3)\n",
    "embeddings = weights.get_weights()[0]\n",
    "embeddings = np.nan_to_num(embeddings / np.linalg.norm(embeddings, axis = 1).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_closest(query, embedding_matrix, word_idx, idx_word, n = 10, least = False):\n",
    "    \"\"\"Find closest words to a query word in embeddings\"\"\"\n",
    "    \n",
    "    idx = word_idx.get(query, None)\n",
    "    # Handle case where query is not in vocab\n",
    "    if idx is None:\n",
    "        print(f'{query} not found in vocab.')\n",
    "        return\n",
    "    else:\n",
    "        vec = embedding_matrix[idx]\n",
    "        # Handle case where word doesn't have an embedding\n",
    "        if np.all(vec == 0):\n",
    "            print(f'{query} has no pre-trained embedding.')\n",
    "            return\n",
    "        else:\n",
    "            # Calculate distance between vector and all others\n",
    "            dists = np.dot(embedding_matrix, vec)\n",
    "            \n",
    "            if least:\n",
    "                idxs = np.argsort(dists)[:n]\n",
    "            else:\n",
    "                # Sort indexes in reverse order\n",
    "                idxs = np.argsort(dists)[::-1][:n]\n",
    "            sorted_dists = dists[idxs]\n",
    "            closest = [idx_word[i] for i in idxs]\n",
    "            \n",
    "    print(f'Query: {query}\\n')\n",
    "    # Print out the word and cosine distances\n",
    "    for word, dist in zip(closest, sorted_dists):\n",
    "        print(f'Word: {word:15} Cosine Similarity: {round(dist, 4)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: the\n",
      "\n",
      "Word: the             Cosine Similarity: 1.0\n",
      "Word: Shameless       Cosine Similarity: 0.5835999846458435\n",
      "Word: beautiful       Cosine Similarity: 0.5300999879837036\n",
      "Word: bush            Cosine Similarity: 0.5097000002861023\n",
      "Word: Gong            Cosine Similarity: 0.48829999566078186\n",
      "Word: West            Cosine Similarity: 0.4878999888896942\n",
      "Word: polluted        Cosine Similarity: 0.4844000041484833\n",
      "Word: favourably      Cosine Similarity: 0.48410001397132874\n",
      "Word: b-              Cosine Similarity: 0.47769999504089355\n",
      "Word: Farrah          Cosine Similarity: 0.476500004529953\n"
     ]
    }
   ],
   "source": [
    "find_closest('the', embeddings, word_index, index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What\n",
      "\n",
      "Word: What            Cosine Similarity: 1.0\n",
      "Word: partner         Cosine Similarity: 0.9140999913215637\n",
      "Word: analysis        Cosine Similarity: 0.9042999744415283\n",
      "Word: Goku            Cosine Similarity: 0.9035999774932861\n",
      "Word: grand           Cosine Similarity: 0.9021999835968018\n",
      "Word: marries         Cosine Similarity: 0.9018999934196472\n",
      "Word: accounting      Cosine Similarity: 0.9014999866485596\n",
      "Word: stressed        Cosine Similarity: 0.8956999778747559\n",
      "Word: internal        Cosine Similarity: 0.8952999711036682\n",
      "Word: trait           Cosine Similarity: 0.8942000269889832\n"
     ]
    }
   ],
   "source": [
    "find_closest('What', embeddings, word_index, index_word, n = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.2280687 ,  0.00167013, -0.19859864, -0.14022546, -0.1431441 ,\n",
       "       -0.20457116,  0.0107323 , -0.12995672, -0.02073253,  0.15847164,\n",
       "       -0.17600329,  0.11368658, -0.02655024,  0.2282364 ,  0.00058332,\n",
       "       -0.2165317 ,  0.0007019 ,  0.20995955,  0.10638271, -0.02124753,\n",
       "       -0.23224181, -0.00416978, -0.00148469, -0.07528396,  0.23424476,\n",
       "        0.24503402, -0.01487264,  0.20249258,  0.05425905, -0.03641619,\n",
       "       -0.22361198,  0.01788967,  0.18893792, -0.00886964,  0.02122222,\n",
       "        0.00866623, -0.10659754, -0.02448355, -0.20074952,  0.20973067,\n",
       "       -0.00746605, -0.03333661,  0.0397941 ,  0.21455634, -0.15770036,\n",
       "        0.11095827, -0.07149883, -0.05746122, -0.28492412,  0.07802176],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[word_index['How']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.09921692"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embeddings[word_index['the']], embeddings[word_index['The']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.60075325"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.dot(embeddings[word_index['What']], embeddings[word_index['How']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(arr):\n",
    "    return np.nan_to_num(arr / np.linalg.norm(arr, axis = 1).reshape((-1, 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "glove_embeddings = np.load('glove_embeddings.npy')\n",
    "glove_embeddings = normalize(glove_embeddings)\n",
    "fasttext_embeddings = np.load('fasttext_embeddings.npy')\n",
    "fasttext_embeddings = normalize(fasttext_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/2\n",
      "914285/914285 [==============================] - 485s 530us/step - loss: 0.1336 - binary_accuracy: 0.9519 - binary_crossentropy: 0.1336 - f1: 0.5128 - val_loss: 0.1127 - val_binary_accuracy: 0.9556 - val_binary_crossentropy: 0.1127 - val_f1: 0.6005\n",
      "Epoch 2/2\n",
      "914285/914285 [==============================] - 485s 530us/step - loss: 0.1019 - binary_accuracy: 0.9603 - binary_crossentropy: 0.1019 - f1: 0.6417 - val_loss: 0.1126 - val_binary_accuracy: 0.9563 - val_binary_crossentropy: 0.1126 - val_f1: 0.6146\n",
      "\n",
      "CuDNN LSTM model took 972.47 seconds.\n"
     ]
    }
   ],
   "source": [
    "model = get_model(vs, 'glove_embeddings', layers.CuDNNLSTM(32), glove_embeddings)\n",
    "start = timer()\n",
    "history = model.fit(sequences, labels, callbacks=model.callbacks,\n",
    "                    epochs = 2, validation_split = 0.3,\n",
    "                    batch_size=512, verbose = 1)\n",
    "end = timer()\n",
    "print(f'\\nCuDNN LSTM model took {end - start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN Attempt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_6 (InputLayer)         (None, 492)               0         \n",
      "_________________________________________________________________\n",
      "embedding (Embedding)        (None, 492, 300)          17918400  \n",
      "_________________________________________________________________\n",
      "conv1d_7 (Conv1D)            (None, 488, 128)          192128    \n",
      "_________________________________________________________________\n",
      "max_pooling1d_7 (MaxPooling1 (None, 97, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_8 (Conv1D)            (None, 93, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_8 (MaxPooling1 (None, 18, 128)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_9 (Conv1D)            (None, 14, 128)           82048     \n",
      "_________________________________________________________________\n",
      "max_pooling1d_9 (MaxPooling1 (None, 2, 128)            0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 18,307,649\n",
      "Trainable params: 18,307,649\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=[<tf.Tenso..., outputs=[<tf.Tenso...)`\n"
     ]
    }
   ],
   "source": [
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "\n",
    "embedding_matrix = glove_embeddings\n",
    "\n",
    "MAX_SEQUENCE_LENGTH = sequences.shape[1]\n",
    "\n",
    "sequence_input = Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')\n",
    "\n",
    "embedding_layer = Embedding(embedding_matrix.shape[0], \n",
    "                             embedding_matrix.shape[1],\n",
    "                             weights = [embedding_matrix],\n",
    "                             name = 'embedding')\n",
    "\n",
    "embedded_sequences = embedding_layer(sequence_input)\n",
    "\n",
    "l_cov1= Conv1D(128, 5, activation='relu')(embedded_sequences)\n",
    "l_pool1 = MaxPooling1D(5)(l_cov1)\n",
    "l_cov2 = Conv1D(128, 5, activation='relu')(l_pool1)\n",
    "l_pool2 = MaxPooling1D(5)(l_cov2)\n",
    "l_cov3 = Conv1D(128, 5, activation='relu')(l_pool2)\n",
    "l_pool3 = MaxPooling1D(5)(l_cov3)  # global max pooling\n",
    "l_flat = Flatten()(l_pool3)\n",
    "l_dense = Dense(128, activation='relu')(l_flat)\n",
    "l_dense = Dropout(0.5)(l_dense)\n",
    "preds = Dense(1, activation='sigmoid')(l_dense)\n",
    "                          \n",
    "model = Model(inputs = [sequence_input], output = [preds])\n",
    "\n",
    "model.compile(optimizer = optimizers.Adam(), loss = losses.binary_crossentropy,\n",
    "              metrics = [metrics.binary_crossentropy, metrics.binary_accuracy,\n",
    "                         f1])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'cnn'\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "                 callbacks.ModelCheckpoint(filepath=f'models/{model_name}.h5',\n",
    "                                           save_best_only=True, save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/5\n",
      "914285/914285 [==============================] - 198s 216us/step - loss: 0.2455 - binary_crossentropy: 0.2455 - binary_accuracy: 0.9382 - f1: 0.0000e+00 - val_loss: 0.2330 - val_binary_crossentropy: 0.2330 - val_binary_accuracy: 0.9380 - val_f1: 0.0000e+00\n",
      "Epoch 2/5\n",
      "914285/914285 [==============================] - 194s 212us/step - loss: 0.2366 - binary_crossentropy: 0.2366 - binary_accuracy: 0.9382 - f1: 9.7808e-05 - val_loss: 0.2341 - val_binary_crossentropy: 0.2341 - val_binary_accuracy: 0.9380 - val_f1: 0.0000e+00\n",
      "Epoch 3/5\n",
      "914285/914285 [==============================] - 194s 212us/step - loss: 0.2365 - binary_crossentropy: 0.2365 - binary_accuracy: 0.9382 - f1: 3.6721e-05 - val_loss: 0.2329 - val_binary_crossentropy: 0.2329 - val_binary_accuracy: 0.9380 - val_f1: 0.0000e+00\n",
      "Epoch 4/5\n",
      "914285/914285 [==============================] - 193s 211us/step - loss: 0.2359 - binary_crossentropy: 0.2359 - binary_accuracy: 0.9382 - f1: 1.4375e-04 - val_loss: 0.2326 - val_binary_crossentropy: 0.2326 - val_binary_accuracy: 0.9380 - val_f1: 0.0000e+00\n",
      "Epoch 5/5\n",
      "914285/914285 [==============================] - 193s 212us/step - loss: 0.2356 - binary_crossentropy: 0.2356 - binary_accuracy: 0.9382 - f1: 1.5180e-04 - val_loss: 0.2326 - val_binary_crossentropy: 0.2326 - val_binary_accuracy: 0.9380 - val_f1: 0.0000e+00\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(sequences, labels, validation_split = 0.3, \n",
    "                    callbacks = callback_list, epochs = 5,\n",
    "                    batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-3536571a9bc3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/wjk68/.local/lib/python3.6/site-packages/ipykernel_launcher.py:2: RuntimeWarning: invalid value encountered in true_divide\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "e = model.get_layer('embedding')\n",
    "w = normalize(e.get_weights()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What\n",
      "\n",
      "Word: What            Cosine Similarity: 1.0\n",
      "Word: Why             Cosine Similarity: 0.7633000016212463\n",
      "Word: How             Cosine Similarity: 0.737500011920929\n",
      "Word: Does            Cosine Similarity: 0.7138000130653381\n",
      "Word: That            Cosine Similarity: 0.6886000037193298\n",
      "Word: Where           Cosine Similarity: 0.6687999963760376\n",
      "Word: Is              Cosine Similarity: 0.6633999943733215\n",
      "Word: Did             Cosine Similarity: 0.6583999991416931\n",
      "Word: Can             Cosine Similarity: 0.6425999999046326\n",
      "Word: Know            Cosine Similarity: 0.6338000297546387\n"
     ]
    }
   ],
   "source": [
    "find_closest('What', w, word_index, index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "shapes (50,) and (300,) not aligned: 50 (dim 0) != 300 (dim 0)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-e5ee1ad818d6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'What'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mglove_embeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'What'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m: shapes (50,) and (300,) not aligned: 50 (dim 0) != 300 (dim 0)"
     ]
    }
   ],
   "source": [
    "np.dot(embeddings[word_index['What']], glove_embeddings[word_index['What']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: What\n",
      "\n",
      "Word: What            Cosine Similarity: 1.0\n",
      "Word: How             Cosine Similarity: 0.7607\n",
      "Word: That            Cosine Similarity: 0.758\n",
      "Word: Which           Cosine Similarity: 0.7509\n",
      "Word: Where           Cosine Similarity: 0.7486\n",
      "Word: Why             Cosine Similarity: 0.7375\n",
      "Word: Now             Cosine Similarity: 0.7356\n",
      "Word: Whatever        Cosine Similarity: 0.712\n",
      "Word: So              Cosine Similarity: 0.7073\n",
      "Word: Do              Cosine Similarity: 0.7065\n"
     ]
    }
   ],
   "source": [
    "find_closest('What', fasttext_embeddings, word_index, index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest('What', embeddings, word_index, index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings.shape, fasttext_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "embedding_2_input (InputLayer)  (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, None)         0           embedding_2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "lambda_4 (Lambda)               (None, None)         0           embedding_2_input[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "sequential_2 (Sequential)       (None, 1)            18116161    lambda_3[0][0]                   \n",
      "                                                                 lambda_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_6 (Concatenate)           (None, 1)            0           sequential_2[1][0]               \n",
      "                                                                 sequential_2[2][0]               \n",
      "==================================================================================================\n",
      "Total params: 18,116,161\n",
      "Trainable params: 18,116,161\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = get_model(vs, 'glove_model', layers.CuDNNLSTM(64), embeddings = glove_embeddings)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 914285 samples, validate on 391837 samples\n",
      "Epoch 1/10\n",
      "914285/914285 [==============================] - 395s 432us/step - loss: 0.0935 - binary_accuracy: 0.9631 - binary_crossentropy: 0.0935 - f1: 0.6749 - val_loss: 0.1222 - val_binary_accuracy: 0.9550 - val_binary_crossentropy: 0.1222 - val_f1: 0.5875\n",
      "Epoch 2/10\n",
      "914285/914285 [==============================] - 395s 433us/step - loss: 0.0813 - binary_accuracy: 0.9677 - binary_crossentropy: 0.0813 - f1: 0.7199 - val_loss: 0.1418 - val_binary_accuracy: 0.9543 - val_binary_crossentropy: 0.1418 - val_f1: 0.6016\n",
      "Epoch 3/10\n",
      "914285/914285 [==============================] - 395s 432us/step - loss: 0.0695 - binary_accuracy: 0.9721 - binary_crossentropy: 0.0695 - f1: 0.7617 - val_loss: 0.1566 - val_binary_accuracy: 0.9522 - val_binary_crossentropy: 0.1566 - val_f1: 0.5762\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(sequences, labels, \n",
    "                    callbacks = model.callbacks,\n",
    "                    epochs = 10, validation_split = 0.3, \n",
    "                    batch_size = 2048)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('glove_embeddings.json', 'w') as f:\n",
    "    f.write(json.dumps(glove_embeddings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings['the']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "find_closest('the', glove_embeddings, word_index, index_word, least = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = [k[0] for k in keep]\n",
    "ord(keep_words[-1][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '/home/wjk68/data/quora/glove.840B.300d/glove.840B.300d.txt'\n",
    "    \n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = np.zeros((vs, len(embeddings_index['the'])))\n",
    "\n",
    "not_in = 0\n",
    "for w, i in word_index.items():\n",
    "    if w in embeddings_index.keys():\n",
    "        glove_embeddings[i, :] = embeddings_index[w]\n",
    "    else:\n",
    "        not_in += 1\n",
    "        \n",
    "print(f'There are {not_in} words with no pre-trained embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.getsizeof(embeddings_index) / 1e9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_FILE = '/home/wjk68/data/quora/wiki-news-300d-1M/wiki-news-300d-1M.vec'\n",
    "    \n",
    "def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "fasttext_embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasttext_embeddings = np.zeros((vs, len(embeddings_index['the'])))\n",
    "\n",
    "not_in = 0\n",
    "\n",
    "for w, i in word_index.items():\n",
    "    if w in fasttext_embeddings_index.keys():\n",
    "        fasttext_embeddings[i, :] = fasttext_embeddings_index[w]\n",
    "    else:\n",
    "        not_in += 1\n",
    "        \n",
    "print(f'There are {not_in} words with no pre-trained embeddings.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_glove(word_index):\n",
    "    EMBEDDING_FILE = '/home/wjk68/data/quora/glove.840B.300d/glove.840B.300d.txt'\n",
    "    \n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "\n",
    "    all_embs = np.stack(embeddings_index.values())\n",
    "    emb_mean,emb_std = -0.005838499,0.48782197\n",
    "    embed_size = all_embs.shape[1]\n",
    "\n",
    "    # word_index = tokenizer.word_index\n",
    "    nb_words = min(max_features, len(word_index))\n",
    "    embedding_matrix = np.random.normal(emb_mean, emb_std, (nb_words, embed_size))\n",
    "    for word, i in word_index.items():\n",
    "        if i >= max_features: continue\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None: embedding_matrix[i] = embedding_vector\n",
    "            \n",
    "    return embedding_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove_embeddings = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ord('\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(8221)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chr(8217)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(keep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep_words = [x[0] for x in keep]\n",
    "len(keep_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word[58635]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "keep[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wi = dict(list(word_index.items())[:len(keep)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = {word: index for word, index in word_index.items() if word in keep_words}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "index_word = {index: word for word, index in word_index.items()}\n",
    "len(index_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "cudnn_model = models.Sequential()\n",
    "cudnn_model.add(layers.Embedding(vs, 50))\n",
    "cudnn_model.add(layers.CuDNNLSTM(64, return_sequences=False))\n",
    "cudnn_model.add(layers.Dense(64, activation='relu'))\n",
    "cudnn_model.add(layers.Dropout(0.5))\n",
    "cudnn_model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "cudnn_model.compile(optimizer=optimizers.Adam(), loss=losses.binary_crossentropy)\n",
    "_ = cudnn_model.fit(sequences, labels, batch_size=8192, epochs = 1)\n",
    "end = timer()\n",
    "print(f'\\nCuDNN LSTM model took {end - start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "model = models.Sequential()\n",
    "model.add(layers.Embedding(vs, 50))\n",
    "model.add(layers.LSTM(64, return_sequences=False))\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.5))\n",
    "model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(), loss=losses.binary_crossentropy)\n",
    "_ = model.fit(sequences, labels, batch_size=8192, epochs = 1)\n",
    "end = timer()\n",
    "print(f'\\nKeras LSTM model took {end - start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_model(vs, 'lstm_model', layers.LSTM(64, return_sequences = False))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "history = cudnn_model.fit(sequences, labels,\n",
    "                          batch_size=8192, epochs=1)\n",
    "end = timer()\n",
    "print(f'\\nCuDNN LSTM model took {end - start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "history = model.fit(sequences, labels,\n",
    "                          batch_size=8192, epochs=1,\n",
    "                          verbose=1, validation_split=0.2,\n",
    "                          callbacks=model.callbacks)\n",
    "end = timer()\n",
    "print(f'\\nKeras LSTM model took {end - start:.2f} seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vs = len(word_index) + 1\n",
    "\n",
    "# Create model on cpu\n",
    "with tf.device('/cpu:0'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(vs, 50))\n",
    "    model.add(layers.Bidirectional(\n",
    "        layers.CuDNNLSTM(64, return_sequences=False)))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = multi_gpu_model(model, gpus=len(get_available_gpus()))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy,  metrics.binary_crossentropy, f1])\n",
    "\n",
    "\n",
    "model_name = 'first_try'\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "                 callbacks.ModelCheckpoint(filepath=f'models/{model_name}.h5',\n",
    "                                           save_best_only=True, save_weights_only=False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "history = model.fit(\n",
    "    sequences,\n",
    "    labels,\n",
    "    batch_size=8192,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callback_list)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{end - start:.2f} seconds for CuDNN LSTM layer.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create model on cpu\n",
    "with tf.device('/cpu:0'):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Embedding(vs, 50))\n",
    "    model.add(layers.LSTM(64, return_sequences=False,\n",
    "                          dropout=0.5, recurrent_dropout=0.2))\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(32, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model = multi_gpu_model(model, gpus=len(get_available_gpus()))\n",
    "\n",
    "model.compile(optimizer=optimizers.Adam(),\n",
    "              loss=losses.binary_crossentropy,\n",
    "              metrics=[metrics.binary_accuracy,  metrics.binary_crossentropy, f1])\n",
    "\n",
    "\n",
    "model_name = 'first_try'\n",
    "\n",
    "callback_list = [callbacks.EarlyStopping(monitor='val_loss', patience=2),\n",
    "                 callbacks.ModelCheckpoint(filepath=f'models/{model_name}.h5',\n",
    "                                           save_best_only=True, save_weights_only=False)]\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = timer()\n",
    "history = model.fit(\n",
    "    sequences,\n",
    "    labels,\n",
    "    batch_size=8192,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    validation_split=0.2,\n",
    "    callbacks=callback_list)\n",
    "end = timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'{end - start:.2f} seconds for LSTM version.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.load_model('models/first_try.h5',\n",
    "                          custom_objects={'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = pd.read_csv(datadir + 'test.csv')\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_texts = list(test['question_text'])\n",
    "test_sequences = tokenizer.texts_to_sequences(test_texts)\n",
    "test_sequences = pad_sequences(test_sequences, max(lens))\n",
    "test_sequences = np.array(test_sequences, dtype=int)\n",
    "test_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_sequences, batch_size=8192,\n",
    "                            verbose=1)\n",
    "predictions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0], test_texts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[1], test_texts[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "\n",
    "for ii, p in enumerate(predictions):\n",
    "    if p > 0.5:\n",
    "        i += 1\n",
    "        print(p, test_texts[ii])\n",
    "        if i > 10:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dirs = ['paragram_300_sl999/', 'glove.840B.300d/']\n",
    "glove_dir = datadir + embeddings_dirs[1] + 'glove.840B.300d.txt'\n",
    "\n",
    "\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype='float32')\n",
    "\n",
    "\n",
    "embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(glove_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = list(train[''])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc - l / home/wjk68/data/quora/paragram_300_sl999/paragram_300_sl999.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!wc - l / home/wjk68/data/quora/glove.840B.300d/glove.840B.300d.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings_dirs = ['paragram_300_sl999/', 'glove.840B.300d/']\n",
    "paragram = np.loadtxt(\n",
    "    datadir + embeddings_dirs[0] + 'paragram_300_sl999.txt', dtype=str)\n",
    "paragram.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.listdir(datadir + '/' + 'paragram_300_sl999')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
